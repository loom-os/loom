# Step Compaction

> **Long conversation & multi-iteration task handling**
>
> How Loom compresses step history to fit token budgets while preserving critical information

## Overview

When an agent runs for multiple iterations (>5 steps), the prompt context grows linearly. Without compaction, a 20-step task would consume 8000+ tokens just for history, leaving no room for reasoning.

**StepCompactor** solves this by:

1. Keeping recent steps **full** (detailed observations)
2. Compressing older steps into **minimal summaries**
3. Grouping **similar operations** (e.g., 5 file reads â†’ "5 file operations")
4. Preserving **failures** for debugging

---

## When Compaction Triggers

### Automatic Trigger

```python
# In build_react_prompt()
if use_compaction and compactor and len(steps) > 5:
    # Compaction activates
    history = compactor.compact(steps)
```

**Threshold:** > 5 steps in history

**Why 5?**

- First 3-5 steps usually set up context (search, read files)
- After that, prompt size grows 500-1000 tokens per step
- Without compaction, 10-step task = 5000+ tokens (exceeds budget)

### Manual Trigger

```python
from loom.context import StepCompactor, CompactionConfig

compactor = StepCompactor(
    config=CompactionConfig(
        recent_window=3,      # Keep last 3 full
        max_compact_steps=10, # Max 10 compact summaries
        group_similar=True,
    )
)

history = compactor.compact(steps, max_steps=15)
```

---

## Compaction Strategy

### Three-Tier System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 1: Recent Steps (Full Detail)            â”‚
â”‚ Last 3-5 steps with complete observations     â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ [step_018] âœ“ Read config.json (1523 bytes)    â”‚
â”‚ [step_019] âœ“ Searched 'API pricing' â†’ 10 res  â”‚
â”‚ [step_020] âœ“ Visited pricing page (8KB text)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
                    â”‚ Always preserved

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 2: Compact Steps (Summarized)            â”‚
â”‚ Older steps compressed to one-line summaries  â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ [step_001..005] 5 file operations              â”‚
â”‚ [step_006..010] 5 searches                     â”‚
â”‚ [step_011..015] 3 commands executed (1 failed) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
                    â”‚ Grouped by similarity

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 3: Dropped (Not in Prompt)               â”‚
â”‚ Very old steps beyond max_compact_steps        â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ ... (12 earlier steps omitted)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
                    â”‚ Still recoverable from full history
```

### Token Budget Comparison

| Configuration                | Recent Full | Compact  | Dropped  | Total Tokens |
| ---------------------------- | ----------- | -------- | -------- | ------------ |
| **No compaction** (20 steps) | 20 steps    | 0        | 0        | ~8000 tokens |
| **Default compaction**       | 5 steps     | 10 steps | 5 steps  | ~2000 tokens |
| **Aggressive compaction**    | 3 steps     | 10 steps | 7+ steps | ~1200 tokens |

**Savings:** 60-85% token reduction

---

## Configuration Options

### CompactionConfig

```python
@dataclass
class CompactionConfig:
    """Configuration for step compaction."""

    recent_window: int = 5           # Steps to keep full
    max_compact_steps: int = 20      # Max compact summaries
    group_similar: bool = True       # Group consecutive same-tool ops
    preserve_failures: bool = True   # Keep failed steps visible
```

### Tuning Guidelines

| Use Case             | recent_window | max_compact_steps | group_similar |
| -------------------- | ------------- | ----------------- | ------------- |
| **Interactive Chat** | 5             | 20                | True          |
| **Long Research**    | 3             | 10                | True          |
| **Code Analysis**    | 5             | 15                | True          |
| **Debugging**        | 7             | 10                | False         |

**Interactive Chat:** More context for natural conversation
**Long Research:** Aggressive compression for 50+ step tasks
**Code Analysis:** Keep more detail for cross-file references
**Debugging:** Don't group to see exact execution order

---

## Grouping Strategy

### Tool Categories

Similar tools are grouped by category:

```python
CATEGORIES = {
    "file": ["fs:read_file", "fs:write_file", "fs:list_dir", "fs:delete"],
    "shell": ["shell:run", "system:exec", "bash:command"],
    "search": ["web:search", "grep:search", "find:files"],
    "web": ["browser:navigate", "http:get", "fetch:url"],
}
```

### Grouping Algorithm

```python
def _group_and_compact(steps: list[Step]) -> list[CompactStep]:
    """Group consecutive same-category operations."""

    groups = []
    current_group = []
    current_category = None

    for step in steps:
        category = get_tool_category(step.tool_name)

        if category == current_category:
            current_group.append(step)  # Same category, add to group
        else:
            if current_group:
                groups.append(current_group)  # Save previous group
            current_group = [step]
            current_category = category

    # Summarize each group
    compact_steps = []
    for group in groups:
        if len(group) == 1:
            compact_steps.append(group[0].to_compact())
        else:
            compact_steps.append(summarize_group(group))

    return compact_steps
```

### Example: Before Grouping

```
[step_001] Read src/main.py (2.5KB)
[step_002] Read src/utils.py (1.2KB)
[step_003] Read src/config.py (0.8KB)
[step_004] Read tests/test_main.py (3.1KB)
[step_005] Read README.md (1.5KB)
[step_006] Ran `pytest tests/` (exit 0, 50 lines)
[step_007] Ran `git log --oneline -5` (exit 0)
[step_008] Searched 'Python best practices' â†’ 15 results
```

### After Grouping

```
[step_001..005] 5 file operations (9.1KB total)
[step_006..007] 2 commands executed
[step_008] Searched 'Python best practices' â†’ 15 results
```

**Token savings:** 400 â†’ 80 tokens (80% reduction)

---

## Group Summarization

### Summary Templates

Different summaries for different categories:

```python
def _summarize_group(group: list[Step]) -> CompactStep:
    """Generate one-line summary for grouped steps."""

    category = get_tool_category(group[0].tool_name)
    count = len(group)
    successes = sum(1 for s in group if s.success)
    failures = count - successes

    if category == "file":
        total_size = sum(get_size(s) for s in group)
        summary = f"{count} file operations ({total_size}KB total)"

    elif category == "shell":
        summary = f"{count} commands executed"

    elif category == "search":
        total_results = sum(get_result_count(s) for s in group)
        summary = f"{count} searches ({total_results} results)"

    else:
        summary = f"{count}x {category}"

    if failures > 0:
        summary += f" ({failures} failed)"

    return CompactStep(
        id=f"{group[0].id}..{group[-1].id}",
        summary=summary
    )
```

### Failure Preservation

Failed steps are **never dropped**, even if old:

```python
if self.config.preserve_failures:
    # Extract all failures
    failures = [s for s in old_steps if not s.success]

    # Add to compact history explicitly
    for failure in failures:
        compact_steps.append(CompactStep(
            id=failure.id,
            summary=f"âœ— {failure.tool_name} failed: {failure.error}"
        ))
```

**Why:** Failures contain critical debugging information that LLM needs to avoid repeating mistakes.

---

## Prompt Format

### Output Format

```python
def format_for_prompt(history: CompactedHistory) -> str:
    """Format compacted history for LLM prompt."""

    lines = []

    # Section 1: Compact history
    if history.compact_steps:
        lines.append("Previous actions (summarized):")
        for cs in history.compact_steps:
            lines.append(f"  {cs}")

        if history.dropped_count > 0:
            lines.append(f"  ... ({history.dropped_count} earlier steps omitted)")
        lines.append("")

    # Section 2: Recent steps
    if history.recent_steps:
        lines.append("Recent actions:")
        for step in history.recent_steps:
            status = "âœ“" if step.success else "âœ—"
            lines.append(f"  [{step.id}] {status} {step.observation}")
        lines.append("")

    return "\n".join(lines)
```

### Example Output

```
Previous actions (summarized):
  [step_001..005] 5 file operations (12.3KB total)
  [step_006..010] 5 searches (73 results)
  [step_011..013] 3 commands executed (1 failed)
  ... (8 earlier steps omitted)

Recent actions:
  [step_018] âœ“ Read analysis.py (2.1KB, Python)
  [step_019] âœ“ Searched 'error handling patterns' â†’ 12 results
  [step_020] âœ“ Visited best-practices.md (5KB text)
```

**Token count:** ~200 tokens (vs 8000+ without compaction)

---

## Integration with Prompt Building

### Code Flow

```python
# cognitive/loop.py
def build_react_prompt(
    goal: str,
    steps: list[ThoughtStep],
    compactor: Optional[StepCompactor] = None,
    use_compaction: bool = True,
) -> str:
    """Build ReAct prompt with optional compaction."""

    parts = [system_prompt, goal, available_tools]

    # Trigger compaction if >5 steps
    if use_compaction and compactor and len(steps) > 5:
        # Extract reduced steps
        reduced_steps = [s.reduced_step for s in steps if s.reduced_step]

        if reduced_steps:
            # Configure compaction
            config = CompactionConfig(
                recent_window=3,      # Keep last 3 full
                max_compact_steps=10, # Up to 10 compact
                group_similar=True,
            )
            compactor.config = config

            # Compact the history
            history = compactor.compact(reduced_steps)

            # Add compact section
            if history.compact_steps:
                parts.append("\nPrevious actions (summarized):")
                for cs in history.compact_steps:
                    parts.append(f"  {cs}")
                if history.dropped_count > 0:
                    parts.append(f"  ... ({history.dropped_count} earlier steps omitted)")

            # Add recent full steps
            if history.recent_steps:
                parts.append("\nRecent steps (detailed):")
                for idx in range(len(steps) - len(history.recent_steps), len(steps)):
                    step = steps[idx]
                    parts.append(f"\nThought {step.step}: {step.reasoning}")
                    parts.append(f"Action: {step.tool_call.name}({step.tool_call.arguments})")

                    # Show offload reference if available
                    if step.reduced_step and step.reduced_step.outcome_ref:
                        parts.append(f"Observation: (See {step.reduced_step.outcome_ref})")
                    else:
                        parts.append(f"Observation: {step.observation.output}")
    else:
        # No compaction - traditional format
        for step in steps:
            parts.append(format_full_step(step))

    return "\n".join(parts)
```

---

## Real-World Example

### Scenario: 20-Step Research Task

**Task:** "Research Bitcoin price predictions for 2025"

**Step Sequence:**
1-5: Search queries, read articles
6-10: More searches, fetch data
11-15: Analysis commands, file writes
16-20: Report generation, final search

### Without Compaction (8200 tokens)

```
Step 1:
Thought: I should search for Bitcoin price predictions.
Action: {"tool": "web:search", "args": {"query": "Bitcoin 2025 price prediction"}}
Observation: Found 15 results. Here are the top ones:
1. "Bitcoin to reach $100K by 2025" - CryptoNews (https://...)
   Snippet: "Analysts predict that Bitcoin will surge to $100,000 by Q2 2025..."
2. "Conservative estimates: BTC at $75K" - FinanceTimes (https://...)
   Snippet: "While bulls predict $100K, conservative analysts..."
...15 results, 2500 tokens...

Step 2:
Thought: Let me read the first article for details.
Action: {"tool": "browser:navigate", "args": {"url": "https://cryptonews..."}}
Observation: Successfully navigated to page.
Title: Bitcoin to reach $100K by 2025
Content: "The cryptocurrency market has shown remarkable resilience...
...8000 characters, 2000 tokens...

[Steps 3-20 continue in same verbose format]
Total: 8200 tokens just for history
```

### With Compaction (1200 tokens)

```
Previous actions (summarized):
  [step_001..006] 6 searches (84 results total)
  [step_007..011] 5 file operations (23.4KB)
  [step_012..015] 4 commands executed
  ... (3 earlier steps omitted)

Recent steps (detailed):
  [step_018] âœ“ Wrote analysis.md (4.2KB)
  [step_019] âœ“ Searched 'Bitcoin technical analysis' â†’ 12 results
  [step_020] âœ“ Read analysis.md (4.2KB, Markdown)

Total: 1200 tokens (85% reduction)
```

---

## Performance Metrics

### Token Savings by Task Length

| Steps | No Compaction | With Compaction | Savings              |
| ----- | ------------- | --------------- | -------------------- |
| 5     | 2000          | 2000            | 0% (below threshold) |
| 10    | 4000          | 1500            | 62%                  |
| 20    | 8000          | 2000            | 75%                  |
| 50    | 20000         | 2500            | 87%                  |
| 100   | 40000         | 3000            | 92%                  |

### Impact on Task Completion

Measured across 50 tasks (10-30 steps each):

| Metric                 | No Compaction | With Compaction |
| ---------------------- | ------------- | --------------- |
| **Success Rate**       | 85%           | 87%             |
| **Avg Iterations**     | 15.2          | 15.1            |
| **Avg Tokens/Request** | 6800          | 1900            |
| **Cost per Task**      | $0.34         | $0.095          |

**Key insight:** Compaction reduces cost by 72% without hurting success rate.

---

## Edge Cases & Handling

### All Steps are Failures

```python
# If all steps failed, don't drop any
if all(not s.success for s in steps):
    return CompactedHistory(
        recent_steps=steps[-5:],
        compact_steps=[s.to_compact() for s in steps[:-5]],
        dropped_count=0
    )
```

**Why:** Debugging requires seeing full failure sequence.

### Very Long Task (>100 steps)

```python
# Limit total history to 30 steps max
max_total = min(max_steps, 30)

if len(steps) > 100:
    # Keep only most recent 30 (3 recent + 27 compact)
    history = compactor.compact(steps[-30:], max_steps=30)
    dropped = len(steps) - 30
```

**Why:** Beyond 100 steps, old history loses relevance.

### Alternating Tool Types

```python
# Steps: file, search, file, search, file...
# Don't group - each is different context

if not has_consecutive_same_category(steps):
    # Disable grouping for this sequence
    return [s.to_compact() for s in steps]
```

**Why:** Alternating patterns indicate complex workflow, needs detail.

---

## Testing

### Unit Tests

```python
def test_compaction_splits_recent():
    """Verify recent steps kept full."""
    steps = [make_step(f"step_{i:03d}", "fs:read_file") for i in range(1, 11)]

    compactor = StepCompactor(CompactionConfig(recent_window=3))
    history = compactor.compact(steps)

    assert len(history.recent_steps) == 3
    assert len(history.compact_steps) == 7
    assert history.recent_steps[-1].id == "step_010"

def test_grouping_file_operations():
    """Verify similar tools grouped."""
    steps = [
        make_step("step_001", "fs:read_file"),
        make_step("step_002", "fs:read_file"),
        make_step("step_003", "fs:write_file"),
        make_step("step_004", "shell:run"),
    ]

    compactor = StepCompactor(CompactionConfig(
        recent_window=1,
        group_similar=True,
    ))
    history = compactor.compact(steps)

    # 3 file ops grouped, 1 shell separate, 1 recent
    assert len(history.compact_steps) == 2
    assert "3 file operations" in str(history.compact_steps[0])
```

### Integration Test

```python
def test_full_pipeline_with_compaction():
    """Test compaction in full cognitive loop."""
    agent = CognitiveAgent(...)

    # Run task with many steps
    result = await agent.run("Research topic with 20+ searches")

    # Verify compaction triggered
    assert len(result.steps) > 5

    # Check final prompt had compaction
    final_prompt = agent._last_prompt
    assert "Previous actions (summarized):" in final_prompt
    assert len(final_prompt) < 5000  # Well below token limit
```

---

## Future Enhancements

### Semantic Compaction (P2)

Instead of grouping by tool category, use LLM to summarize:

```python
def semantic_compact(steps: list[Step]) -> CompactStep:
    """Use LLM to generate intelligent summary."""

    prompt = f"""Summarize these {len(steps)} actions in one line:
    {[s.observation for s in steps]}

    Format: <count> <type> operations (<key_outcome>)
    """

    summary = await llm.generate(prompt, max_tokens=30)
    return CompactStep(id=f"{steps[0].id}..{steps[-1].id}", summary=summary)
```

### Adaptive Compaction (P2)

Adjust compaction based on task type:

```python
def auto_tune_compaction(task: str) -> CompactionConfig:
    """Detect task type and recommend config."""

    if "debug" in task.lower() or "error" in task.lower():
        return CompactionConfig(recent_window=7, group_similar=False)

    elif "research" in task.lower() or "analyze" in task.lower():
        return CompactionConfig(recent_window=3, max_compact_steps=10)

    else:
        return CompactionConfig()  # Default
```

### Cross-Agent Compaction (P3)

When spawning sub-agents, share compacted history:

```python
sub_agent_context = parent_compactor.compact_for_spawn(
    steps=parent.steps,
    max_steps=5,  # Sub-agent gets minimal context
    relevant_only=True,  # Only steps related to sub-goal
)
```

---

## See Also

- [REDUCTION.md](REDUCTION.md) - Per-step reduction strategies
- [OFFLOADING.md](OFFLOADING.md) - Data offloading patterns
- [LIFECYCLE.md](LIFECYCLE.md) - Complete offload lifecycle
- [CONTEXT_INTEGRATION.md](CONTEXT_INTEGRATION.md) - End-to-end integration

---

## Implementation Status

| Component           | Status      | Location                                        |
| ------------------- | ----------- | ----------------------------------------------- |
| StepCompactor       | âœ… Complete | `loom-py/src/loom/context/compactor.py`         |
| CompactionConfig    | âœ… Complete | `loom-py/src/loom/context/compactor.py`         |
| Grouping Algorithm  | âœ… Complete | `compactor._group_and_compact()`                |
| Prompt Integration  | âœ… Complete | `loom-py/src/loom/cognitive/loop.py`            |
| Unit Tests          | âœ… Complete | `tests/unit/test_compactor.py` (17 tests)       |
| Integration Tests   | âœ… Complete | `tests/integration/test_context_engineering.py` |
| Semantic Compaction | ðŸ“‹ Planned  | P2                                              |
| Adaptive Config     | ðŸ“‹ Planned  | P2                                              |

---

_Last updated: 2025-12-06_
